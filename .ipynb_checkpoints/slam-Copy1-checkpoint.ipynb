{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt, pi\n",
    "path = loadtxt(r\"C:\\Users\\localadmin.TUD0035314\\Documents\\GitHub\\New_world\\robot_trajectory.txt\")\n",
    "poses = []\n",
    "for i in range(len(path)):\n",
    "    if path[i][3]!=0:\n",
    "        if path[i][3] == 1:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],pi])\n",
    "        elif path[i][3] == 3:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],0])\n",
    "        elif path[i][3] == 2:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],3*pi/2])\n",
    "        elif path[i][3] == 4:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],pi/2])\n",
    "\n",
    "lposes = len(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from math import tan, atan, sqrt, cos, sin\n",
    "from numpy import eye, diag, array, exp, ceil, floor, dot, arange\n",
    "from numpy.linalg import inv, det\n",
    "from random import gauss, randint, uniform\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self,pose):\n",
    "        self.pose = pose\n",
    "        self.landmark_poses = []\n",
    "        self.landmark_covariances = []\n",
    "        self.wall_list = [] # Stores the histogram from the tree w\n",
    "        self.var = 0\n",
    "        self.length = 480\n",
    "        self.w = [['0'],['90'],['180'],['270']] # Landmark as histograms stored by each particle\n",
    "        self.tree = []\n",
    "        \n",
    "    def tree_map(poses):\n",
    "\n",
    "        l = self.length\n",
    "        ww =  30\n",
    "        for j in range(4): # Wall type\n",
    "            wo = poses[3]*(180/pi)\n",
    "            if wo == int(self.w[j][0]): # Correspond the measurement to the leaf of the tree\n",
    "                if wo % 180 == 0:\n",
    "                    m = 0 # Flag to check for update\n",
    "                    for k in range(len(self.w[j])):\n",
    "                        if poses[0] == self.w[j][k][0]:\n",
    "                            self.dis_Bayes(self.w[j][k][1],int(poses[1]),20) # wall_list[w[j][k][1]][int(poses[1])] = 1\n",
    "                            m = 1\n",
    "\n",
    "                    if m == 0:\n",
    "                        # Create a new list and update them\n",
    "                        r = 0\n",
    "                        if len(self.w[(j+2)%4]) != 1:\n",
    "                            for k in arange(1,len(self.w[(j+2)%4]),1):\n",
    "                                if (poses[0]-ww) == self.w[(j+2)%4][k][0]:\n",
    "                                    self.w[j].insert(1,[poses[0],self.w[(j+2)%4][k][1]])\n",
    "                                    self.dis_Bayes(self.w[(j+2)%4][k][1],int(poses[1]),20)\n",
    "        #                             wall_list[w[(j+2)%4][k][1]][int(poses[1])] = 1\n",
    "                                    r = 1\n",
    "                                elif (poses[0]+ww) == self.w[(j+2)%4][k][0]:\n",
    "                                    self.w[j].insert(1,[poses[0],self.w[(j+2)%4][k][1]])\n",
    "                                    self.dis_Bayes(self.w[(j+2)%4][k][1],int(poses[1]),20)\n",
    "        #                             wall_list[w[(j+2)%4][k][1]][int(poses[1])] = 1\n",
    "                                    r = 1\n",
    "                        if r == 0:\n",
    "                            self.w[j].insert(1,[poses[0],self.var])\n",
    "                            self.wall_list.append([1/l]*l)\n",
    "                            self.dis_Bayes(self.var,int(poses[1]),20)\n",
    "                            self.var=self.var+1\n",
    "\n",
    "                else:\n",
    "                    m = 0\n",
    "                    for k in range(len(self.w[j])):\n",
    "                        if poses[1] == self.w[j][k][0]:\n",
    "        #                     wall_list[w[j][k][1]][int(poses[0])] = 1\n",
    "                            self.dis_Bayes(self.w[j][k][1],int(poses[0]),20)\n",
    "                            m = 1\n",
    "                    if m == 0:\n",
    "                        # Create a new list\n",
    "                        r = 0\n",
    "                        if len(self.w[(j+2)%4]) != 1:\n",
    "                            for k in arange(1,len(self.w[(j+2)%4]),1):\n",
    "                                if poses[1]-ww == self.w[(j+2)%4][k][1]: \n",
    "                                    self.w[j].insert(1,[poses[1]-ww,self.w[(j+2)%4][k][1]])\n",
    "                                    self.dis_Bayes(self.w[(j+2)%4][k][1],int(poses[0]),20)\n",
    "        #                             wall_list[w[(j+2)%4][k][1]][int(poses[0])] = 1\n",
    "                                    r = 1\n",
    "                                elif poses[1]+ww == self.w[(j+2)%4][k][0]: \n",
    "                                    self.w[j].insert(1,[poses[1]+ww,self.w[(j+2)%4][k][1]])\n",
    "                                    self.dis_Bayes(self.w[(j+2)%4][k][1],int(poses[0]),20)\n",
    "        #                             wall_list[w[(j+2)%4][k][1]][int(poses[0])] = 1\n",
    "                                    r = 1\n",
    "                        if r == 0:\n",
    "                            self.w[j].insert(1,[poses[1],self.var])\n",
    "                            self.wall_list.append([1/l]*l)\n",
    "                            self.dis_Bayes(self.var,int(poses[0]),20)\n",
    "                            self.var=self.var+1\n",
    "                        \n",
    "    def dis_Bayes(self,wall_num, index, index_sttdev): # The landmark, the position of measurement of \n",
    "        # that landmark and stddev(covariance)\n",
    "        \n",
    "        for i in range(index_stddev):\n",
    "            # Corridor width=120, Standard deviation=11, Creating a triangular distribution of width=2sigma\n",
    "            b=1.5-i*(0.5/index_stddev) \n",
    "            if j-i >= 0: \n",
    "                self.wall_list[wall_num][index-i]*=b\n",
    "            if j+i <=l-1:\n",
    "                self.wall_list[wall_num][index+i]*=b\n",
    "\n",
    "            self.wall_list[wall_num] = [i*5/sum(wall_list[wall_num]) for i in a] # Scaling parameter=5\n",
    "    \n",
    "    def number_of_landmarks(self):\n",
    "        return self.var # len(self.landmark_poses)\n",
    "    \n",
    "    @staticmethod\n",
    "    def motion(pose, control, WB, dt):  \n",
    "        angle = (control[1]+pose[2])%(2*pi)\n",
    "        return ([x+y for x,y in zip(pose,[control[0]*dt*cos(angle),\n",
    "                                          control[0]*dt*sin(angle),\n",
    "                                          control[0]*dt*sin(control[1])/WB])])\n",
    "    \n",
    "    def move(self,control,WB,dt,pose):\n",
    "        self.pose = pose\n",
    "        \n",
    "    def expected_measurement(self,pose,landmark,i):   # Not considering the other component  \n",
    "        return array([landmark[0],tan(landmark[1]-pose[2])])      \n",
    "    \n",
    "    def measurement_correspondence(self,pose,measurement,number_of_landmarks,Qt_measurement_covariance):\n",
    "        likelihoods = []\n",
    "        for i in range(number_of_landmarks):\n",
    "            likelihoods.append(self.landmark_correspondence(measurement,i,Qt_measurement_covariance))\n",
    "        return likelihoods\n",
    "    \n",
    "    @staticmethod\n",
    "    def dh_dlandmark(pose,landmark):\n",
    "        return array([[1,0,0],[0,1,0],[0,0,-1/(cos(pose[2]-landmark[2])**2)]]) # H - Direct odometry measurement and collision\n",
    "    \n",
    "    def H_and_Ql_from_measurement(self,landmark_number,Qt_measurement_covariance):\n",
    "        \n",
    "        H = self.dh_dlandmark(self.pose,self.landmark_poses[landmark_number])\n",
    "        Ql = dot(dot(H,self.landmark_covariances[landmark_number]),H.T) + Qt_measurement_covariance\n",
    "        \n",
    "        return (H, Ql)\n",
    "        \n",
    "    def landmark_correspondence_likelihood(self,measurement,landmark_number,Qt_measurement_covariance):\n",
    "        # For a given measurment and a landmark number, it returns a suitable likelihood value of the correspondence\n",
    "\n",
    "        landmark = self.w[landmark_number]\n",
    "        num_wall = len(landmark)-1\n",
    "        \n",
    "        for i in arange(1,num_wall,1):\n",
    "            \n",
    "            phi = landmark[i][1]\n",
    "            theta = self.pose[2]\n",
    "\n",
    "            # Prune the landmark which are not in the robot's frame of collision\n",
    "            if phi == pi/2 * floor(theta/(pi/2)) or phi == pi/2 * ceil(theta/(pi/2)): \n",
    "                if landmark[i][1] % pi == 0:\n",
    "                    # Check the x-value correspondence\n",
    "                    zhat = self.expected_measurement(self.pose,landmark[i])\n",
    "                else:\n",
    "                    # Check the y-value correspondence\n",
    "                    \n",
    "                    \n",
    "                zhat = self.expected_measurement(self.pose,landmark)\n",
    "                H, Ql = self.H_and_Ql_from_measurement(landmark_number,Qt_measurement_covariance)\n",
    "                dz = measurement - zhat\n",
    "                # Compute likelihood\n",
    "                sqrtdetQl = sqrt(det(Ql))\n",
    "                normal = 1 / (2*pi*sqrtdetQl)\n",
    "                l = normal * exp(-0.5*dot(dot(dz.T,inv(Ql)),dz))            \n",
    "            else: \n",
    "                l = 0\n",
    "        return l\n",
    "    \n",
    "    def initialize_new_landmark(self,measurement,Qt_measurement_covariance, l):\n",
    "        # Measurement to be modified (Orientations to 90 degrees)\n",
    "        self.w.insert(self.var,[self.var])        \n",
    "        orientation = self.pose[2]+atan(measurement[2])\n",
    "        \n",
    "        Hinv = array([[1,0,0],[0,1,0],[0,0,1/(1+measurement[2]**2)]])\n",
    "        Sigma = dot(dot(Hinv,Qt_measurement_covariance),Hinv.T)\n",
    "        \n",
    "        if orientation % pi == 0:\n",
    "            self.w[self.var].append([poses[0], orientation])\n",
    "            self.wall_list.append([1/l]*l)\n",
    "            self.dis_Bayes(self.var,int(poses[1]),20)\n",
    "            self.landmark_covariances.append(Sigma[0][0])\n",
    "        else:\n",
    "            self.w[self.var].append([poses[1], orientation])\n",
    "            self.wall_list.append([1/l]*l)\n",
    "            self.dis_Bayes(self.var,int(poses[0]),20)   \n",
    "            self.landmark_covariances.append(Sigma[1][1])\n",
    "            \n",
    "        self.var = self.var + 1\n",
    "        \n",
    "    def update_landmark(self,measurement,landmark_number,Qt_measurement_covariance):\n",
    "        \n",
    "        mu = self.landmark_poses[landmark_number]\n",
    "        Sigma = self.landmark_covariances[landmark_number]\n",
    "        H, Ql = self.H_and_Ql_from_measurement(landmark_number,Qt_measurement_covariance)\n",
    "        K = dot(dot(Sigma,H.T),inv(Ql))\n",
    "        \n",
    "        mu = mu + dot(K,(measurement - self.expected_measurement(self.pose,mu)))\n",
    "        Sigma = dot((eye(3) - K*H),Sigma)\n",
    "        \n",
    "        return (mu,Sigma)\n",
    "    \n",
    "    def update_particle(self,measurement,number_of_landmarks,minimum_correspondence_likelihood,Qt_measurement_covariance):\n",
    "        likelihoods = []\n",
    "        for i in range(number_of_landmarks):\n",
    "            likelihoods.append(self.landmark_correspondence_likelihood(measurement,i,Qt_measurement_covariance))\n",
    "\n",
    "        if not likelihoods or max(likelihoods) < minimum_correspondence_likelihood:\n",
    "            self.initialize_new_landmark(measurement,Qt_measurement_covariance, self.length)\n",
    "            return minimum_correspondence_likelihood\n",
    "        \n",
    "        else:\n",
    "            lmax = max(likelihoods)\n",
    "            lmax_index = likelihoods.index(lmax)\n",
    "            mu,Sigma = self.update_landmark(measurement,lmax_index,Qt_measurement_covariance)\n",
    "            self.landmark_poses[lmax_index] = mu\n",
    "            self.landmark_covariances[lmax_index] = Sigma\n",
    "            \n",
    "            return lmax\n",
    "\n",
    "class FastSLAM:\n",
    "    def __init__(self,initial_particles,robot_width,minimum_correspondence_likelihood,measurement_stddev,\n",
    "                 x_stddev,y_stddev,control_speed_factor,control_head_factor, sample_time):\n",
    "        # Particles\n",
    "        self.particles = initial_particles\n",
    "        \n",
    "        # Constants\n",
    "        self.robot_width = robot_width\n",
    "        self.minimum_correspondence_likelihood = minimum_correspondence_likelihood\n",
    "        self.xstddev = xstddev\n",
    "        self.ystddev = ystddev\n",
    "        self.measurement_stddev = measurement_stddev\n",
    "        self.control_speed_factor = control_speed_factor\n",
    "        self.control_head_factor = control_head_factor\n",
    "        self.dt = sample_time\n",
    "        self.WB = robot_width\n",
    "        \n",
    "    def predict(self,pose,control):\n",
    "        # Prediction step of FastSLAM\n",
    "\n",
    "        speed, head = control\n",
    "        speed_std = self.control_speed_factor * sqrt(speed) # To be modified\n",
    "        head_std  = self.control_head_factor * sqrt(359 - head) # To be modified; mirror image of the speed deviation\n",
    "        \n",
    "        for p in self.particles:\n",
    "            speed = gauss(speed,speed_std)\n",
    "            head = gauss(head,head_std)\n",
    "            p.move([speed,head],self.WB,self.dt,pose)\n",
    "    \n",
    "    def update_and_compute_weights(self,measurement):\n",
    "\n",
    "        Qt_measurement_covariance = diag([self.xstddev ** 2, self.ystddev ** 2,self.measurement_stddev ** 2]) \n",
    "        weights = []\n",
    "        for p in self.particles:\n",
    "            number_of_landmarks = p.number_of_landmarks()\n",
    "            weight = p.update_particle(measurement,number_of_landmarks,self.minimum_correspondence_likelihood,\n",
    "                                            Qt_measurement_covariance)\n",
    "            weights.append(weight)\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def resample(self,weights):\n",
    "        \n",
    "        new_particles = []\n",
    "        max_weight = max(weights)\n",
    "        index = randint(0, len(self.particles)-1)\n",
    "        offset = 0.0\n",
    "        for i in xrange(len(self.particles)):\n",
    "            offset += uniform(0, 2.0 * max_weight)\n",
    "            while offset > weights[index]:\n",
    "                offset -= weights[index]\n",
    "                index = (index + 1) % len(weights)\n",
    "            new_particles.append(copy.deepcopy(self.particles[index]))\n",
    "            \n",
    "        return new_particles\n",
    "    \n",
    "    def correct(self,measurement):\n",
    "        \n",
    "        tree_map()\n",
    "\n",
    "        weights = self.update_and_compute_weights(measurement)\n",
    "        self.particles = self.resample(weights)\n",
    "        \n",
    "        return weights\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    robot_width = 2\n",
    "    sample_time = 0.01\n",
    "    \n",
    "    minimum_correspondence_likelihood = 1e-3\n",
    "    xstddev = 0.001\n",
    "    ystddev = 0.001\n",
    "    measurement_stddev = 0.001\n",
    "    \n",
    "    control_speed_factor = 0.01\n",
    "    control_head_factor = 0.01\n",
    "    number_of_particles = 10\n",
    "    \n",
    "    start_state = poses[0][0:3]\n",
    "    initial_particles = [copy.copy(Particle(start_state))\n",
    "                         for _ in xrange(number_of_particles)]\n",
    "\n",
    "    fs = FastSLAM(initial_particles,robot_width,minimum_correspondence_likelihood,measurement_stddev,xstddev,ystddev,\n",
    "                 control_speed_factor,control_head_factor, sample_time)\n",
    "    \n",
    "    for i in xrange(lposes-1):\n",
    "        # Correction step\n",
    "        print \"Iteration\",i\n",
    "        '''Use of entire trajectory for the correction step (Rao-Blackwellization)''' \n",
    "        w = fs.correct(array([poses[i][0],poses[i][1],tan(poses[i][3]-poses[i][2])])) # Odometry and collision values\n",
    "        #Prediction\n",
    "        fs.predict(poses[i+1][0:3],[100,poses[i+1][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "\n",
    "xl = []\n",
    "yl = []\n",
    "xt = []\n",
    "yt = []\n",
    "\n",
    "for i in xrange(len(fs.particles[0].landmark_poses)):\n",
    "    xl.append(fs.particles[0].landmark_poses[i][0])\n",
    "    yl.append(fs.particles[0].landmark_poses[i][1])\n",
    "    xt.append(poses[i][0])\n",
    "    yt.append(poses[i][1])\n",
    "\n",
    "plt.plot(xl,yl,'o',color='b')\n",
    "plt.plot(xt,yt,'o',color='r')\n",
    "plt.show()\n",
    "print \"xl is\",xl\n",
    "print \"yl is\",yl\n",
    "print \"xt is\",xt\n",
    "print \"yt is\",yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[111.5, 0]]]\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "f1=[]\n",
    "a.insert(0,f1)\n",
    "f1.append([111.5,0])\n",
    "print a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
