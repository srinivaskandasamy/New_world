{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt, pi\n",
    "path = loadtxt(r\"C:\\Users\\localadmin.TUD0035314\\Documents\\GitHub\\New_world\\robot_trajectory.txt\")\n",
    "poses = []\n",
    "for i in range(len(path)):\n",
    "    if path[i][3]!=0:\n",
    "        if path[i][3] == 1:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],pi])\n",
    "        elif path[i][3] == 3:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],0])\n",
    "        elif path[i][3] == 2:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],3*pi/2])\n",
    "        elif path[i][3] == 4:\n",
    "            poses.append([path[i][0],path[i][1],path[i-1][2],pi/2])\n",
    "\n",
    "poses = poses[0:7]\n",
    "lposes = len(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\n"
     ]
    }
   ],
   "source": [
    "from math import tan, atan, sqrt, cos, sin\n",
    "from numpy import eye, diag, array, exp, ceil, floor, dot\n",
    "from numpy.linalg import inv, det\n",
    "from random import gauss, randint, uniform\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self,pose):\n",
    "        self.pose = pose\n",
    "        self.landmark_poses = []\n",
    "        self.landmark_covariances = []\n",
    "        \n",
    "    def number_of_landmarks(self):\n",
    "        return len(self.landmark_poses)\n",
    "    \n",
    "    @staticmethod\n",
    "    def motion(pose, control, WB, dt):  \n",
    "        angle = (control[1]+pose[2])%(2*pi)\n",
    "        return ([x+y for x,y in zip(pose,[control[0]*dt*cos(angle),\n",
    "                                          control[0]*dt*sin(angle),\n",
    "                                          control[0]*dt*sin(control[1])/WB])])\n",
    "    \n",
    "    def move(self,control,WB,dt,pose):\n",
    "        self.pose = pose\n",
    "        \n",
    "    def expected_measurement(self,pose,landmark):\n",
    "        theta = pose[2]\n",
    "        phi = landmark[2]        \n",
    "        return array([pose[0],pose[1],tan(phi-theta)]) # Ratio of the accelerations ax/ay       \n",
    "    \n",
    "    def measurement_correspondence(self,pose,measurement,number_of_landmarks,Qt_measurment_covariance):\n",
    "        likelihoods = []\n",
    "        for i in range(number_of_landmarks):\n",
    "            likelihoods.append(self.landmark_correspondence(measurement,i,Qt_measurment_covariance))\n",
    "        return likelihoods\n",
    "    \n",
    "    @staticmethod\n",
    "    def dh_dlandmark(pose,landmark):\n",
    "        return array([[1,0,0],[0,1,0],[0,0,-1/(cos(pose[2]-landmark[2])**2)]]) # H - Direct odometry measurement and collision\n",
    "    \n",
    "    def H_and_Ql_from_measurement(self,landmark_number,Qt_measurement_covariance):\n",
    "        \n",
    "        H = self.dh_dlandmark(self.pose,self.landmark_poses[landmark_number])\n",
    "        Ql = dot(dot(H,self.landmark_covariances[landmark_number]),H.T) + Qt_measurement_covariance\n",
    "        \n",
    "        return (H, Ql)\n",
    "        \n",
    "    def landmark_correspondence_likelihood(self,measurement,landmark_number,Qt_measurement_covariance):\n",
    "        # For a given measurment and a landmark number, it returns a suitable likelihood value of the correspondence\n",
    "\n",
    "        landmark = self.landmark_poses[landmark_number]\n",
    "        phi = landmark[2]\n",
    "        theta = self.pose[2]\n",
    "        \n",
    "        # Prune the landmark which are not in the robot's frame of collision\n",
    "        if phi == pi/2 * floor(theta/(pi/2)) or phi == pi/2 * ceil(theta/(pi/2)): \n",
    "            zhat = self.expected_measurement(self.pose,landmark)\n",
    "            H, Ql = self.H_and_Ql_from_measurement(landmark_number,Qt_measurement_covariance)\n",
    "            dz = measurement - zhat\n",
    "            # Compute likelihood\n",
    "            sqrtdetQl = sqrt(det(Ql))\n",
    "            normal = 1 / (2*pi*sqrtdetQl)\n",
    "            l = normal * exp(-0.5*dot(dot(dz.T,inv(Ql)),dz))            \n",
    "        else: \n",
    "            l = 0\n",
    "        return l\n",
    "    \n",
    "    def initialize_new_landmark(self,measurement,Qt_measurement_covariance):\n",
    "\n",
    "        self.landmark_poses.append([self.pose[0],self.pose[1],self.pose[2]+atan(measurement[2])]) # Orientation update as FSM\n",
    "        # We have to modify the orientation of the landmark to multiples of 90 degrees\n",
    "        Hinv = array([[1,0,0],[0,1,0],[0,0,1/(1+measurement[2]**2)]])\n",
    "        Sigma = Hinv*Qt_measurement_covariance*Hinv.T\n",
    "        # Remember to add the covariance of the particle at that moment\n",
    "        \n",
    "        self.landmark_covariances.append(Sigma)\n",
    "        \n",
    "    def update_landmark(self,measurement,landmark_number,Qt_measurement_covariance):\n",
    "        \n",
    "        mu = self.landmark_poses[landmark_number]\n",
    "        Sigma = self.landmark_covariances[landmark_number]\n",
    "        H, Ql = self.H_and_Ql_from_measurement(landmark_number,Qt_measurement_covariance)\n",
    "        K = dot(dot(Sigma,H.T),inv(Ql))\n",
    "        \n",
    "        mu = mu + dot(K,(measurement - self.expected_measurement(self.pose,mu)))\n",
    "        Sigma = dot((eye(3) - K*H),Sigma)\n",
    "        \n",
    "        return (mu,Sigma)\n",
    "    \n",
    "    def update_particle(self,measurement,number_of_landmarks,minimum_correspondence_likelihood,Qt_measurement_covariance):\n",
    "\n",
    "        likelihoods = []\n",
    "        for i in range(number_of_landmarks):\n",
    "            likelihoods.append(self.landmark_correspondence_likelihood(measurement,i,Qt_measurement_covariance))\n",
    "            \n",
    "        if not likelihoods or max(likelihoods) < minimum_correspondence_likelihood:\n",
    "            self.initialize_new_landmark(measurement,Qt_measurement_covariance)\n",
    "            return minimum_correspondence_likelihood\n",
    "        \n",
    "        else:\n",
    "            lmax = max(likelihoods)\n",
    "            lmax_index = likelihoods.index(lmax)\n",
    "            mu,Sigma = self.update_landmark(measurement,lmax_index,Qt_measurement_covariance)\n",
    "            self.landmark_poses[lmax_index] = mu\n",
    "            self.landmark_covariances[lmax_index] = Sigma\n",
    "            \n",
    "            return lmax\n",
    "\n",
    "class FastSLAM:\n",
    "    def __init__(self,initial_particles,robot_width,minimum_correspondence_likelihood,measurement_stddev,\n",
    "                 x_stddev,y_stddev,control_speed_factor,control_head_factor, sample_time):\n",
    "        # Particles\n",
    "        self.particles = initial_particles\n",
    "        \n",
    "        # Constants\n",
    "        self.robot_width = robot_width\n",
    "        self.minimum_correspondence_likelihood = minimum_correspondence_likelihood\n",
    "        self.xstddev = xstddev\n",
    "        self.ystddev = ystddev\n",
    "        self.measurement_stddev = measurement_stddev\n",
    "        self.control_speed_factor = control_speed_factor\n",
    "        self.control_head_factor = control_head_factor\n",
    "        self.dt = sample_time\n",
    "        self.WB = robot_width\n",
    "        \n",
    "    def predict(self,pose,control):\n",
    "        # Prediction step of FastSLAM\n",
    "\n",
    "        speed, head = control\n",
    "        speed_std = self.control_speed_factor * sqrt(speed) # To be modified\n",
    "        head_std  = self.control_head_factor * sqrt(359 - head) # To be modified; mirror image of the speed deviation\n",
    "        \n",
    "        for p in self.particles:\n",
    "            speed = gauss(speed,speed_std)\n",
    "            head = gauss(head,head_std)\n",
    "            p.move([speed,head],self.WB,self.dt,pose)\n",
    "    \n",
    "    def update_and_compute_weights(self,measurement):\n",
    "\n",
    "        Qt_measurement_covariance = diag([self.xstddev ** 2, self.ystddev ** 2,self.measurement_stddev ** 2]) \n",
    "        weights = []\n",
    "        for p in self.particles:\n",
    "            number_of_landmarks = p.number_of_landmarks()\n",
    "            weight = p.update_particle(measurement,number_of_landmarks,self.minimum_correspondence_likelihood,\n",
    "                                            Qt_measurement_covariance)\n",
    "            weights.append(weight)\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def resample(self,weights):\n",
    "        \n",
    "        new_particles = []\n",
    "        max_weight = max(weights)\n",
    "        index = randint(0, len(self.particles)-1)\n",
    "        offset = 0.0\n",
    "        for i in xrange(len(self.particles)):\n",
    "            offset += uniform(0, 2.0 * max_weight)\n",
    "            while offset > weights[index]:\n",
    "                offset -= weights[index]\n",
    "                index = (index + 1) % len(weights)\n",
    "            new_particles.append(copy.deepcopy(self.particles[index]))\n",
    "            \n",
    "        return new_particles\n",
    "    \n",
    "    def correct(self,measurement):\n",
    "\n",
    "        weights = self.update_and_compute_weights(measurement)\n",
    "        self.particles = self.resample(weights)\n",
    "        \n",
    "        return weights\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    robot_width = 2\n",
    "    sample_time = 0.01\n",
    "    \n",
    "    minimum_correspondence_likelihood = 1e-3\n",
    "    xstddev = 0.001\n",
    "    ystddev = 0.001\n",
    "    measurement_stddev = 0.001\n",
    "    \n",
    "    control_speed_factor = 0.01\n",
    "    control_head_factor = 0.01\n",
    "    number_of_particles = 10\n",
    "    \n",
    "    start_state = poses[0][0:3]\n",
    "    initial_particles = [copy.copy(Particle(start_state))\n",
    "                         for _ in xrange(number_of_particles)]\n",
    "\n",
    "    fs = FastSLAM(initial_particles,robot_width,minimum_correspondence_likelihood,measurement_stddev,xstddev,ystddev,\n",
    "                 control_speed_factor,control_head_factor, sample_time)\n",
    "    \n",
    "    for i in xrange(lposes-1):\n",
    "        # Correction step\n",
    "        w = fs.correct(array([poses[i][0],poses[i][1],tan(poses[i][3]-poses[i][2])])) # Odometry and collision values\n",
    "        #Prediction\n",
    "        fs.predict(poses[i+1][0:3],[100,poses[i+1][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xl is [111.5, 22.0, 72.0, 236.0]\n",
      "yl is [161.5, 251.0, 480.0, 316.0]\n",
      "xt is [111.5, 22.0, 111.5, 22.0]\n",
      "yt is [161.5, 251.0, 340.5, 430.0]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "\n",
    "xl = []\n",
    "yl = []\n",
    "xt = []\n",
    "yt = []\n",
    "\n",
    "for i in xrange(len(fs.particles[0].landmark_poses)):\n",
    "    xl.append(fs.particles[0].landmark_poses[i][0])\n",
    "    yl.append(fs.particles[0].landmark_poses[i][1])\n",
    "    xt.append(poses[i][0])\n",
    "    yt.append(poses[i][1])\n",
    "\n",
    "plt.plot(xl,yl,'o',color='b')\n",
    "plt.plot(xt,yt,'o',color='r')\n",
    "plt.show()\n",
    "print \"xl is\",xl\n",
    "print \"yl is\",yl\n",
    "print \"xt is\",xt\n",
    "print \"yt is\",yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111.5, 161.5, 0.78539816339699997, 0], [22.0, 251.0, 2.35619449019, 3.141592653589793], [111.5, 340.5, 0.78539816339699997, 0], [22.0, 430.0, 2.35619449019, 3.141592653589793], [72.0, 480.0, 0.78539816339699997, 1.5707963267948966]]\n"
     ]
    }
   ],
   "source": [
    "print poses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
